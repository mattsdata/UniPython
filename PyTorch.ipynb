{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOIcJWwso13FhpI1vTIBIcf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mattsdata/UniPython/blob/master/PyTorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pytorch Cheatsheet"
      ],
      "metadata": {
        "id": "QdMmR8ATw8ZF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "General"
      ],
      "metadata": {
        "id": "HhK7coxpxNCv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch                                        # root package\n",
        "from torch.utils.data import Dataset, DataLoader    # dataset representation and loading"
      ],
      "metadata": {
        "id": "ZXD5GdGzxBbc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Neural Network API"
      ],
      "metadata": {
        "id": "gnCrZGZoxQti"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.autograd as autograd         # computation graph\n",
        "from torch import Tensor                  # tensor node in the computation graph\n",
        "import torch.nn as nn                     # neural networks\n",
        "import torch.nn.functional as F           # layers, activations and more\n",
        "import torch.optim as optim               # optimizers e.g. gradient descent, ADAM, etc.\n",
        "from torch.jit import script, trace       # hybrid frontend decorator and tracing jit"
      ],
      "metadata": {
        "id": "JICKN46axPrJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "TorchScript and JIT"
      ],
      "metadata": {
        "id": "HPFVOEFHxY0k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.jit.trace()         # takes your module or function and an example\n",
        "                          # data input, and traces the computational steps\n",
        "                          # that the data encounters as it progresses through the model\n",
        "\n",
        "@script                   # decorator used to indicate data-dependent\n",
        "                          # control flow within the code being traced"
      ],
      "metadata": {
        "id": "AFRpC4MYyA_z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ONNX -  Open Neural Network Exchange, is an open-source format for representing deep learning models."
      ],
      "metadata": {
        "id": "P_7vSA6PyDCk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.onnx.export(model, dummy data, xxxx.proto)       # exports an ONNX formatted\n",
        "                                                       # model using a trained model, dummy\n",
        "                                                       # data and the desired file name\n",
        "\n",
        "model = onnx.load(\"alexnet.proto\")                     # load an ONNX model\n",
        "onnx.checker.check_model(model)                        # check that the model\n",
        "                                                       # IR is well formed\n",
        "\n",
        "onnx.helper.printable_graph(model.graph)               # print a human readable\n",
        "                                                       # representation of the graph"
      ],
      "metadata": {
        "id": "lGp1f6IUy3Se"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vision"
      ],
      "metadata": {
        "id": "-8EeFYiny5-D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import datasets, models, transforms     # vision datasets,\n",
        "                                                         # architectures &\n",
        "                                                         # transforms\n",
        "\n",
        "import torchvision.transforms as transforms              # composable transforms"
      ],
      "metadata": {
        "id": "O7ArUyZX0N_8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Distributed Training"
      ],
      "metadata": {
        "id": "kVyaNXUbzB_i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.distributed as dist             # distributed communication\n",
        "from torch.multiprocessing import Process    # memory sharing processes"
      ],
      "metadata": {
        "id": "gIjYjcVh0Qsu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Tensors"
      ],
      "metadata": {
        "id": "fg_wTbT0zEMC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creation"
      ],
      "metadata": {
        "id": "-MxMrL_xzMjJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.randn(*size)              # tensor with independent N(0,1) entries\n",
        "x = torch.[ones|zeros](*size)       # tensor with all 1's [or 0's]\n",
        "x = torch.tensor(L)                 # create tensor from [nested] list or ndarray L\n",
        "y = x.clone()                       # clone of x\n",
        "with torch.no_grad():               # code wrap that stops autograd from tracking tensor history\n",
        "requires_grad=True                  # arg, when set to True, tracks computation\n",
        "                                    # history for future derivative calculations"
      ],
      "metadata": {
        "id": "NZl2l1210Utg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dimensionality"
      ],
      "metadata": {
        "id": "eL_2jhcNzhzs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x.size()                                  # return tuple-like object of dimensions\n",
        "x = torch.cat(tensor_seq, dim=0)          # concatenates tensors along dim\n",
        "y = x.view(a,b,...)                       # reshapes x into size (a,b,...)\n",
        "y = x.view(-1,a)                          # reshapes x into size (b,a) for some b\n",
        "y = x.transpose(a,b)                      # swaps dimensions a and b\n",
        "y = x.permute(*dims)                      # permutes dimensions\n",
        "y = x.unsqueeze(dim)                      # tensor with added axis\n",
        "y = x.unsqueeze(dim=2)                    # (a,b,c) tensor -> (a,b,1,c) tensor\n",
        "y = x.squeeze()                           # removes all dimensions of size 1 (a,1,b,1) -> (a,b)\n",
        "y = x.squeeze(dim=1)                      # removes specified dimension of size 1 (a,1,b,1) -> (a,b,1)"
      ],
      "metadata": {
        "id": "qh3Z1to90fdR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Algebra"
      ],
      "metadata": {
        "id": "h7NfmU5ezjoe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ret = A.mm(B)       # matrix multiplication\n",
        "ret = A.mv(x)       # matrix-vector multiplication\n",
        "x = x.t()           # matrix transpose"
      ],
      "metadata": {
        "id": "JWjH3smT0iL_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "GPU Usage"
      ],
      "metadata": {
        "id": "p3bCnnHRznrL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.is_available                                     # check for cuda\n",
        "x = x.cuda()                                                # move x's data from\n",
        "                                                            # CPU to GPU and return new object\n",
        "\n",
        "x = x.cpu()                                                 # move x's data from GPU to CPU\n",
        "                                                            # and return new object\n",
        "\n",
        "if not args.disable_cuda and torch.cuda.is_available():     # device agnostic code\n",
        "    args.device = torch.device('cuda')                      # and modularity\n",
        "else:                                                       #\n",
        "    args.device = torch.device('cpu')                       #\n",
        "\n",
        "net.to(device)                                              # recursively convert their\n",
        "                                                            # parameters and buffers to\n",
        "                                                            # device specific tensors\n",
        "\n",
        "x = x.to(device)                                            # copy your tensors to a device\n",
        "                                                            # (gpu, cpu)"
      ],
      "metadata": {
        "id": "jl_X8sgE0m-5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Deep Learning"
      ],
      "metadata": {
        "id": "LYHTT2SlzpVF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nn.Linear(m,n)                                # fully connected layer from\n",
        "                                              # m to n units\n",
        "\n",
        "nn.ConvXd(m,n,s)                              # X dimensional conv layer from\n",
        "                                              # m to n channels where X‚ç∑{1,2,3}\n",
        "                                              # and the kernel size is s\n",
        "\n",
        "nn.MaxPoolXd(s)                               # X dimension pooling layer\n",
        "                                              # (notation as above)\n",
        "\n",
        "nn.BatchNormXd                                # batch norm layer\n",
        "nn.RNN/LSTM/GRU                               # recurrent layers\n",
        "nn.Dropout(p=0.5, inplace=False)              # dropout layer for any dimensional input\n",
        "nn.Dropout2d(p=0.5, inplace=False)            # 2-dimensional channel-wise dropout\n",
        "nn.Embedding(num_embeddings, embedding_dim)   # (tensor-wise) mapping from\n",
        "                                              # indices to embedding vectors"
      ],
      "metadata": {
        "id": "05MQ-2pv0o0p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loss Functions"
      ],
      "metadata": {
        "id": "3a4N5XMzzseT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nn.X                                  # where X is L1Loss, MSELoss, CrossEntropyLoss\n",
        "                                      # CTCLoss, NLLLoss, PoissonNLLLoss,\n",
        "                                      # KLDivLoss, BCELoss, BCEWithLogitsLoss,\n",
        "                                      # MarginRankingLoss, HingeEmbeddingLoss,\n",
        "                                      # MultiLabelMarginLoss, SmoothL1Loss,\n",
        "                                      # SoftMarginLoss, MultiLabelSoftMarginLoss,\n",
        "                                      # CosineEmbeddingLoss, MultiMarginLoss,\n",
        "                                      # or TripletMarginLoss"
      ],
      "metadata": {
        "id": "GlW00SX80rPC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Activation Functions"
      ],
      "metadata": {
        "id": "dJRRMJ4ZzuC-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nn.X                                  # where X is ReLU, ReLU6, ELU, SELU, PReLU, LeakyReLU,\n",
        "                                      # RReLu, CELU, GELU, Threshold, Hardshrink, HardTanh,\n",
        "                                      # Sigmoid, LogSigmoid, Softplus, SoftShrink,\n",
        "                                      # Softsign, Tanh, TanhShrink, Softmin, Softmax,\n",
        "                                      # Softmax2d, LogSoftmax or AdaptiveSoftmaxWithLoss"
      ],
      "metadata": {
        "id": "MjrZ34Kc0u3p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Optimizers"
      ],
      "metadata": {
        "id": "Qyru8J6uzyHE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "opt = optim.x(model.parameters(), ...)      # create optimizer\n",
        "opt.step()                                  # update weights\n",
        "optim.X                                     # where X is SGD, Adadelta, Adagrad, Adam,\n",
        "                                            # AdamW, SparseAdam, Adamax, ASGD,\n",
        "                                            # LBFGS, RMSprop or Rprop"
      ],
      "metadata": {
        "id": "-p9dqVnv0xio"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Learning rate scheduling"
      ],
      "metadata": {
        "id": "QbDnGcj-z1he"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scheduler = optim.X(optimizer,...)      # create lr scheduler\n",
        "scheduler.step()                        # update lr after optimizer updates weights\n",
        "optim.lr_scheduler.X                    # where X is LambdaLR, MultiplicativeLR,\n",
        "                                        # StepLR, MultiStepLR, ExponentialLR,\n",
        "                                        # CosineAnnealingLR, ReduceLROnPlateau, CyclicLR,\n",
        "                                        # OneCycleLR, CosineAnnealingWarmRestarts,"
      ],
      "metadata": {
        "id": "pSJhJuVV0-31"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Utilities"
      ],
      "metadata": {
        "id": "FH9-UjtQz4Fj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Datasets"
      ],
      "metadata": {
        "id": "xipBc9Fo0E8a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Dataset                    # abstract class representing dataset\n",
        "TensorDataset              # labelled dataset in the form of tensors\n",
        "Concat Dataset             # concatenation of Datasets"
      ],
      "metadata": {
        "id": "qk_fN94Z1Dnf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataloaders and DataSamplers"
      ],
      "metadata": {
        "id": "7vy2OgCW0JwJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DataLoader(dataset, batch_size=1, ...)      # loads data batches agnostic\n",
        "                                            # of structure of individual data points\n",
        "\n",
        "sampler.Sampler(dataset,...)                # abstract class dealing with\n",
        "                                            # ways to sample from dataset\n",
        "\n",
        "sampler.XSampler where ...                  # Sequential, Random, SubsetRandom,\n",
        "                                            # WeightedRandom, Batch, Distributed"
      ],
      "metadata": {
        "id": "uunjTqiI1H69"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}